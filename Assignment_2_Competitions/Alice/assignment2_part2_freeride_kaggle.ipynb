{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df = pd.read_csv('train_sessions.csv', index_col='session_id', parse_dates=times)\n",
    "test_df = pd.read_csv('test_sessions.csv', index_col='session_id', parse_dates=times)\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites].fillna(0).astype('int').\\\n",
    "                            to_csv('train_sessions_text.txt', sep=' ', index=None, header=None)\n",
    "\n",
    "test_df[sites].fillna(0).astype('int').\\\n",
    "                            to_csv('test_sessions_text.txt', sep=' ', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(ngram_range=(1, 3), max_features=50000)\n",
    "\n",
    "with open('train_sessions_text.txt') as inp_train_file:\n",
    "    X_train = cv.fit_transform(inp_train_file)\n",
    "with open('test_sessions_text.txt') as inp_test_file:\n",
    "    X_test = cv.transform(inp_test_file)\n",
    "    \n",
    "y_train = train_df['target'].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['target']\n",
    "\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_lr(X_train, y_train, C = 1):\n",
    "    time_split = TimeSeriesSplit(n_splits = 10)\n",
    "    logit = LogisticRegression(C = C, random_state = 17, solver = 'liblinear')\n",
    "    \n",
    "    cv_scores = cross_val_score(logit, X_train, y_train, cv = time_split, scoring = 'roc_auc', n_jobs=1)\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score_lr(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.83141992, 0.64671142, 0.87992077, 0.9631551 , 0.84221742,\n",
       "        0.87840646, 0.94476054, 0.85321691, 0.92987691, 0.90752702]),\n",
       " 0.8677212449964109)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new features ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df, X_sparse):\n",
    "    \n",
    "    new_feat = pd.DataFrame(index = df.index)\n",
    "    \n",
    "    new_feat['start_hour'] = df['time1'].apply(lambda ts: ts.hour)\n",
    "    #new_feat['morning'] = new_feat['start_hour'].apply(lambda hour: 1 if (hour >= 7 and hour <= 11) else -1)\n",
    "    #new_feat['day'] = new_feat['start_hour'].apply(lambda hour: 1 if (hour >= 12 and hour <= 18) else -1)\n",
    "    #new_feat['evening'] = new_feat['start_hour'].apply(lambda hour: 1 if (hour >= 19 and hour <= 23) else -1)\n",
    "    #new_feat['night'] = new_feat['start_hour'].apply(lambda hour: 1 if (hour >= 0 or hour <= 6) else -1)\n",
    "    \n",
    "    for i in range(0, 24):\n",
    "        new_feat['hour%s' % i] = df['time1'].apply(lambda ts: 1 if (ts.hour == i) else \\\n",
    "                                (0 if (i in [16, 17, 18, 13, 12, 10]) else -1))\n",
    "    \n",
    "    new_feat['year'] = df['time1'].apply(lambda ts: ts.year).astype('float64') * 100\n",
    "    new_feat['month'] = df['time1'].apply(lambda ts: ts.month).astype('float64')\n",
    "    new_feat['year_month'] = new_feat['year'] + new_feat['month']\n",
    "    scaled_month = StandardScaler().fit_transform(new_feat[['year_month']])    \n",
    "    \n",
    "    new_feat['weekday'] = df['time1'].apply(lambda ts: ts.weekday())\n",
    "    new_feat['duration'] = df[times].max(axis=1) - df[times].min(axis=1)\n",
    "    scaled_duration = StandardScaler().fit_transform(new_feat[['duration']])\n",
    "    \n",
    "    hours = ['hour%s' % i for i in range(0, 24)]\n",
    "    \n",
    "    X = hstack([X_sparse,\n",
    "                new_feat[hours].values.reshape(-1, 24),\n",
    "                scaled_month.reshape(-1, 1),\n",
    "                new_feat['weekday'].values.reshape(-1, 1),\n",
    "                scaled_duration.reshape(-1, 1)\n",
    "               ])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_new = add_time_features(train_df, X_train)\n",
    "X_test_new = add_time_features(test_df, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score_lr(X_train_new, y_train, C=0.21544346900318834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.70637378, 0.79189891, 0.97583175, 0.96016022, 0.93665852,\n",
       "        0.97460733, 0.91460119, 0.95727549, 0.97530845, 0.97908812]),\n",
       " 0.9171803768067142)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=0.21544346900318834, random_state=17, solver='liblinear')\n",
    "logit.fit(X_train_new, y_train)\n",
    "\n",
    "y_test = logit.predict_proba(X_test_new)[:, 1]\n",
    "write_to_submission_file(y_test, 'subm.csv') # 0.9171803768067142 my score, 0.95378 public LB score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00413191, -0.00299359, -0.00512731,  1.22616832,  1.22616832,\n",
       "        1.22616832,  1.22616832,  1.22616832,  1.22616832,  1.22616832,\n",
       "        0.51980673, -1.2406601 , -0.53062623, -2.67722814, -1.33270465,\n",
       "        1.32094346,  0.98424056, -1.1741403 , -0.24360761,  2.62668123,\n",
       "        2.47454044,  2.49684017,  0.09223302,  0.33191412, -0.12119003,\n",
       "        0.08746918,  0.19498534, -0.54908495, -0.33852789, -0.241325  ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.coef_[0][-30:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
